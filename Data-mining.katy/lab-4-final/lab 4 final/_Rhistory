modelosvm<-svm(PurchasedBike~.,data=taprendizaje, kernel="radial", probability=TRUE)
prediccionsvm<-predict(modelosvm, ttesting, probability=TRUE)
prediccionsvm.rocr <- prediction(attr(prediccionsvm, "probabilities")[,2], ttesting$PurchasedBike)
prediccionsvm.perf <- performance(prediccionsvm.rocr, "tpr", "fpr")
plot(prediccionsvm.perf, main="Curva ROC", col="blue")
lines(c(0,1), c(0,1), col="black")
#El area bajo la curva, AUC, esta dada por:
AUCsvm<-as.numeric(slot(performance(prediccionsvm.rocr,"auc"), "y.values"))
AUCsvm
AUCrpart<-1- as.numeric(slot(performance(prediccionrpart.rocr,"auc"), "y.values"))
AUCrpart
legend("bottomright", c(paste("SVM", "AUC:",round(AUCsvm, 3))), lty = c(1,1), lwd=c(2.5,2.5),col=c("blue","red"))
library(rattle)
library(ggplot2)
##Instalacion y carga de las librerias necesarias
install.if.required <- function(x){
if(!require(x, character.only=TRUE)){
install.packages(x, dependencies = TRUE, character.only=TRUE)
library(class, character.only=TRUE)
}
}
lapply(c("class", "e1071", "ROCR","rpart"), install.if.required)
if(!require(class)){
install.packages("class", dependencies = TRUE)
library(class)
}
if(!require(e1071)){
install.packages("e1071", dependencies = TRUE)
library(e1071)
}
if(!require(ROCR)){#   install.packages("ROCR", dependencies = TRUE)
library(ROCR)
}
Datos<-read.table('Comprabicicletas.csv', sep=";", dec=".", header=T)
Datos<-Datos[,-1] #Sacamos la primera columna de la ID de los clientes
head(Datos)
View(Datos)
##Fijamos la semilla de modo de poder comparar los resultados
set.seed(30)
#Generamos una muestra donde el 70% de los datos seran utilizados como tabla de aprendizaje y el 30%como tabla de prueba (testing):
muestra <-sample(1:nrow(Datos),nrow(Datos)%/%(100/30))
ttesting<-Datos[muestra,]
taprendizaje<- Datos[-muestra,]
#Generamos el modelo utilizando la funcion kernel lineal:
modelosvm<-svm(PurchasedBike~.,data=taprendizaje, kernel="linear")
#Realizamos las predicciones sobre la tabla de prueba:
prediccionsvm<-predict(modelosvm, ttesting)
#Calculamos la matriz de confusion y la precision global:
MCsvm<-table(ttesting[,ncol(Datos)],prediccionsvm)
MCsvm
PGsvm<-(sum(diag(MCsvm)))/sum(MCsvm)
PGsvm
#Precision global y matriz de confusion para todos los datos
prediccionsvm.tablacompleta<-predict(modelosvm, Datos)
#Calculamos la matriz de confusion y la precision global:
MCsvm.tablacompleta<-table(Datos[,ncol(Datos)],prediccionsvm.tablacompleta)
MCsvm.tablacompleta
PGsvm.tablacompleta<-(sum(diag(MCsvm.tablacompleta)))/sum(MCsvm.tablacompleta)
PGsvm.tablacompleta
#Metodo de arbol para calcula la matriz de confusicon y la precision global de los datos d eprueba
library(rpart)  #LO MISMO PERO CON ARBOL
modelorpart<-rpart(PurchasedBike~.,data=taprendizaje)
prediccionrpart<-predict(modelorpart, ttesting, type="class")
MCrpart<-table(ttesting[,ncol(Datos)],prediccionrpart)
MCrpart
PGrpart<-(sum(diag(MCrpart)))/sum(MCrpart)
PGrpart
#Metodo de arbol para la tabla copleta
modelorpart<-rpart(PurchasedBike~.,data=taprendizaje)
prediccionrpart.tablacompleta<-predict(modelorpart, Datos, type="class")
MCrpart.tablacompleta<-table(Datos[,ncol(Datos)],prediccionrpart.tablacompleta)
MCrpart.tablacompleta
PGrpart.tablacompleta<-(sum(diag(MCrpart.tablacompleta)))/sum(MCrpart.tablacompleta)
PGrpart.tablacompleta
#DE ACA PA ARRIBA OK
#El siguiente codigo permite construir la curva ROC sin la necesidad de recurrir a rattle:
modelosvm<-svm(PurchasedBike~.,data=taprendizaje, kernel="linear", probability=TRUE)
modelorpart<-rpart(PurchasedBike~.,data=taprendizaje)
prediccionsvm<-predict(modelosvm, ttesting, probability=TRUE)
prediccionrpart<-predict(modelorpart, ttesting, probability=TRUE)
prediccionsvm.rocr <- prediction(attr(prediccionsvm, "probabilities")[,2], ttesting$PurchasedBike)
prediccionrpart.rocr <- prediction(prediccionrpart[,1], ttesting$PurchasedBike)
prediccionsvm.perf <- performance(prediccionsvm.rocr, "tpr", "fpr")
prediccionrpart.perf <- performance(prediccionrpart.rocr, "fpr", "tpr" )
plot(prediccionsvm.perf, main="Curva ROC", col="blue")
plot(prediccionrpart.perf, col="red", add=TRUE)
lines(c(0,1), c(0,1), col="black")
#El area bajo la curva, AUC, esta dada por:
AUCsvm<-as.numeric(slot(performance(prediccionsvm.rocr,"auc"), "y.values"))
AUCsvm
AUCrpart<-1- as.numeric(slot(performance(prediccionrpart.rocr,"auc"), "y.values"))
AUCrpart
legend("bottomright", c(paste("SVM", "AUC:",round(AUCsvm, 3)), paste("rpart", "AUC:", round(AUCrpart,3))), lty = c(1,1), lwd=c(2.5,2.5),col=c("blue","red"))
library(rattle)
library(ggplot2)
##Instalacion y carga de las librerias necesarias
install.if.required <- function(x){
if(!require(x, character.only=TRUE)){
install.packages(x, dependencies = TRUE, character.only=TRUE)
library(class, character.only=TRUE)
}
}
lapply(c("class", "e1071", "ROCR","rpart"), install.if.required)
if(!require(class)){
install.packages("class", dependencies = TRUE)
library(class)
}
if(!require(e1071)){
install.packages("e1071", dependencies = TRUE)
library(e1071)
}
if(!require(ROCR)){#   install.packages("ROCR", dependencies = TRUE)
library(ROCR)
}
Datos<-read.table('Comprabicicletas.csv', sep=";", dec=".", header=T)
Datos<-Datos[,-1] #Sacamos la primera columna de la ID de los clientes
head(Datos)
View(Datos)
##Fijamos la semilla de modo de poder comparar los resultados
set.seed(30)
#Generamos una muestra donde el 70% de los datos seran utilizados como tabla de aprendizaje y el 30%como tabla de prueba (testing):
muestra <-sample(1:nrow(Datos),nrow(Datos)%/%(100/30))
ttesting<-Datos[muestra,]
taprendizaje<- Datos[-muestra,]
#Generamos el modelo utilizando la funcion kernel lineal:
modelosvm<-svm(PurchasedBike~.,data=taprendizaje, kernel="linear")
#Realizamos las predicciones sobre la tabla de prueba:
prediccionsvm<-predict(modelosvm, ttesting)
#Calculamos la matriz de confusion y la precision global:
MCsvm<-table(ttesting[,ncol(Datos)],prediccionsvm)
MCsvm
PGsvm<-(sum(diag(MCsvm)))/sum(MCsvm)
PGsvm
#Precision global y matriz de confusion para todos los datos
prediccionsvm.tablacompleta<-predict(modelosvm, Datos)
#Calculamos la matriz de confusion y la precision global:
MCsvm.tablacompleta<-table(Datos[,ncol(Datos)],prediccionsvm.tablacompleta)
MCsvm.tablacompleta
PGsvm.tablacompleta<-(sum(diag(MCsvm.tablacompleta)))/sum(MCsvm.tablacompleta)
PGsvm.tablacompleta
#Metodo de arbol para calcula la matriz de confusicon y la precision global de los datos d eprueba
library(rpart)  #LO MISMO PERO CON ARBOL
modelorpart<-rpart(PurchasedBike~.,data=taprendizaje)
prediccionrpart<-predict(modelorpart, ttesting, type="class")
MCrpart<-table(ttesting[,ncol(Datos)],prediccionrpart)
MCrpart
PGrpart<-(sum(diag(MCrpart)))/sum(MCrpart)
PGrpart
#Metodo de arbol para la tabla copleta
modelorpart<-rpart(PurchasedBike~.,data=taprendizaje)
prediccionrpart.tablacompleta<-predict(modelorpart, Datos, type="class")
MCrpart.tablacompleta<-table(Datos[,ncol(Datos)],prediccionrpart.tablacompleta)
MCrpart.tablacompleta
PGrpart.tablacompleta<-(sum(diag(MCrpart.tablacompleta)))/sum(MCrpart.tablacompleta)
PGrpart.tablacompleta
#DE ACA PA ARRIBA OK
#El siguiente codigo permite construir la curva ROC sin la necesidad de recurrir a rattle:
modelosvm<-svm(PurchasedBike~.,data=taprendizaje, kernel="linear", probability=TRUE)
modelorpart<-rpart(PurchasedBike~.,data=taprendizaje)
prediccionsvm<-predict(modelosvm, ttesting, probability=TRUE)
prediccionrpart<-predict(modelorpart, ttesting, probability=TRUE)
prediccionsvm.rocr <- prediction(attr(prediccionsvm, "probabilities")[,2], ttesting$PurchasedBike)
prediccionrpart.rocr <- prediction(prediccionrpart[,1], ttesting$PurchasedBike)
prediccionsvm.perf <- performance(prediccionsvm.rocr, "tpr", "fpr")
prediccionrpart.perf <- performance(prediccionrpart.rocr, "fpr", "tpr" )
plot(prediccionsvm.perf, main="Curva ROC", col="blue")
plot(prediccionrpart.perf, col="red", add=TRUE)
lines(c(0,1), c(0,1), col="black")
#El area bajo la curva, AUC, esta dada por:
AUCsvm<-as.numeric(slot(performance(prediccionsvm.rocr,"auc"), "y.values"))
AUCsvm
AUCrpart<-1- as.numeric(slot(performance(prediccionrpart.rocr,"auc"), "y.values"))
AUCrpart
legend("bottomright", c(paste("SVM", "AUC:",round(AUCsvm, 3)), paste("rpart", "AUC:", round(AUCrpart,3))), lty = c(1,1), lwd=c(2.5,2.5),col=c("blue","red"))
library(rattle)
library(ggplot2)
##Instalacion y carga de las librerias necesarias
install.if.required <- function(x){
if(!require(x, character.only=TRUE)){
install.packages(x, dependencies = TRUE, character.only=TRUE)
library(class, character.only=TRUE)
}
}
lapply(c("class", "e1071", "ROCR","rpart"), install.if.required)
if(!require(class)){
install.packages("class", dependencies = TRUE)
library(class)
}
if(!require(e1071)){
install.packages("e1071", dependencies = TRUE)
library(e1071)
}
if(!require(ROCR)){#   install.packages("ROCR", dependencies = TRUE)
library(ROCR)
}
Datos<-read.table('Comprabicicletas.csv', sep=";", dec=".", header=T)
Datos<-Datos[,-1] #Sacamos la primera columna de la ID de los clientes
head(Datos)
##Fijamos la semilla de modo de poder comparar los resultados
set.seed(30)
#Generamos una muestra donde el 70% de los datos seran utilizados como tabla de aprendizaje y el 30%como tabla de prueba (testing):
muestra <-sample(1:nrow(Datos),nrow(Datos)%/%(100/30))
ttesting<-Datos[muestra,]
taprendizaje<- Datos[-muestra,]
#Generamos el modelo utilizando la funcion kernel lineal:
modelosvm<-svm(PurchasedBike~.,data=taprendizaje, kernel="linear")
#Realizamos las predicciones sobre la tabla de prueba:
prediccionsvm<-predict(modelosvm, ttesting)
#Calculamos la matriz de confusion y la precision global:
MCsvm<-table(ttesting[,ncol(Datos)],prediccionsvm)
MCsvm
PGsvm<-(sum(diag(MCsvm)))/sum(MCsvm)
PGsvm
#Precision global y matriz de confusion para todos los datos
prediccionsvm.tablacompleta<-predict(modelosvm, Datos)
#Calculamos la matriz de confusion y la precision global:
MCsvm.tablacompleta<-table(Datos[,ncol(Datos)],prediccionsvm.tablacompleta)
MCsvm.tablacompleta
PGsvm.tablacompleta<-(sum(diag(MCsvm.tablacompleta)))/sum(MCsvm.tablacompleta)
PGsvm.tablacompleta
#Metodo de arbol para calcula la matriz de confusicon y la precision global de los datos d eprueba
library(rpart)  #LO MISMO PERO CON ARBOL
modelorpart<-rpart(PurchasedBike~.,data=taprendizaje)
prediccionrpart<-predict(modelorpart, ttesting, type="class")
MCrpart<-table(ttesting[,ncol(Datos)],prediccionrpart)
MCrpart
PGrpart<-(sum(diag(MCrpart)))/sum(MCrpart)
PGrpart
#Metodo de arbol para la tabla copleta
modelorpart<-rpart(PurchasedBike~.,data=taprendizaje)
prediccionrpart.tablacompleta<-predict(modelorpart, Datos, type="class")
MCrpart.tablacompleta<-table(Datos[,ncol(Datos)],prediccionrpart.tablacompleta)
MCrpart.tablacompleta
PGrpart.tablacompleta<-(sum(diag(MCrpart.tablacompleta)))/sum(MCrpart.tablacompleta)
PGrpart.tablacompleta
#DE ACA PA ARRIBA OK
#El siguiente codigo permite construir la curva ROC sin la necesidad de recurrir a rattle:
modelosvm<-svm(PurchasedBike~.,data=taprendizaje, kernel="linear", probability=TRUE)
modelorpart<-rpart(PurchasedBike~.,data=taprendizaje)
prediccionsvm<-predict(modelosvm, ttesting, probability=TRUE)
prediccionrpart<-predict(modelorpart, ttesting, probability=TRUE)
prediccionsvm.rocr <- prediction(attr(prediccionsvm, "probabilities")[,2], ttesting$PurchasedBike)
prediccionrpart.rocr <- prediction(prediccionrpart[,1], ttesting$PurchasedBike)
prediccionsvm.perf <- performance(prediccionsvm.rocr, "tpr", "fpr")
prediccionrpart.perf <- performance(prediccionrpart.rocr, "fpr", "tpr" )
plot(prediccionsvm.perf, main="Curva ROC", col="blue")
plot(prediccionrpart.perf, col="red", add=TRUE)
lines(c(0,1), c(0,1), col="black")
#El area bajo la curva, AUC, esta dada por:
AUCsvm<-as.numeric(slot(performance(prediccionsvm.rocr,"auc"), "y.values"))
AUCsvm
AUCrpart<-1- as.numeric(slot(performance(prediccionrpart.rocr,"auc"), "y.values"))
AUCrpart
legend("bottomright", c(paste("SVM", "AUC:",round(AUCsvm, 3)), paste("rpart", "AUC:", round(AUCrpart,3))), lty = c(1,1), lwd=c(2.5,2.5),col=c("blue","red"))
modelosvm
MCsvm
PGsvm
MCsvm.tablacompleta
PGsvm.tablacompleta
MCrpart
PGrpart
View(Datos)
MCrpart.tablacompleta
PGrpart.tablacompleta
library(rattle)
library(ggplot2)
##Instalacion y carga de las librerias necesarias
install.if.required <- function(x){
if(!require(x, character.only=TRUE)){
install.packages(x, dependencies = TRUE, character.only=TRUE)
library(class, character.only=TRUE)
}
}
lapply(c("class", "e1071", "ROCR","rpart"), install.if.required)
if(!require(class)){
install.packages("class", dependencies = TRUE)
library(class)
}
if(!require(e1071)){
install.packages("e1071", dependencies = TRUE)
library(e1071)
}
if(!require(ROCR)){#   install.packages("ROCR", dependencies = TRUE)
library(ROCR)
}
Datos<-read.table('Comprabicicletas.csv', sep=";", dec=".", header=T)
Datos<-Datos[,-1] #Sacamos la primera columna de la ID de los clientes
head(Datos)
##Fijamos la semilla de modo de poder comparar los resultados
set.seed(30)
#Generamos una muestra donde el 70% de los datos seran utilizados como tabla de aprendizaje y el 30%como tabla de prueba (testing):
muestra <-sample(1:nrow(Datos),nrow(Datos)%/%(100/30))
ttesting<-Datos[muestra,]
taprendizaje<- Datos[-muestra,]
#Generamos el modelo utilizando la funcion kernel lineal:
modelosvm<-svm(PurchasedBike~.,data=taprendizaje, kernel="linear")
#Realizamos las predicciones sobre la tabla de prueba:
prediccionsvm<-predict(modelosvm, ttesting)
#Calculamos la matriz de confusion y la precision global:
MCsvm<-table(ttesting[,ncol(Datos)],prediccionsvm)
MCsvm
PGsvm<-(sum(diag(MCsvm)))/sum(MCsvm)
PGsvm
#Precision global y matriz de confusion para todos los datos
prediccionsvm.tablacompleta<-predict(modelosvm, Datos)
#Calculamos la matriz de confusion y la precision global:
MCsvm.tablacompleta<-table(Datos[,ncol(Datos)],prediccionsvm.tablacompleta)
MCsvm.tablacompleta
PGsvm.tablacompleta<-(sum(diag(MCsvm.tablacompleta)))/sum(MCsvm.tablacompleta)
PGsvm.tablacompleta
#Metodo de arbol para calcula la matriz de confusicon y la precision global de los datos d eprueba
library(rpart)  #LO MISMO PERO CON ARBOL
modelorpart<-rpart(PurchasedBike~.,data=taprendizaje)
prediccionrpart<-predict(modelorpart, ttesting, type="class")
MCrpart<-table(ttesting[,ncol(Datos)],prediccionrpart)
MCrpart
PGrpart<-(sum(diag(MCrpart)))/sum(MCrpart)
PGrpart
#Metodo de arboles de desicion para la tabla copleta
modelorpart<-rpart(PurchasedBike~.,data=taprendizaje)
prediccionrpart.tablacompleta<-predict(modelorpart, Datos, type="class")
MCrpart.tablacompleta<-table(Datos[,ncol(Datos)],prediccionrpart.tablacompleta)
MCrpart.tablacompleta
PGrpart.tablacompleta<-(sum(diag(MCrpart.tablacompleta)))/sum(MCrpart.tablacompleta)
PGrpart.tablacompleta
#El siguiente codigo permite construir la curva ROC sin la necesidad de recurrir a rattle:
modelosvm<-svm(PurchasedBike~.,data=taprendizaje, kernel="linear", probability=TRUE)
modelorpart<-rpart(PurchasedBike~.,data=taprendizaje)
prediccionsvm<-predict(modelosvm, ttesting, probability=TRUE)
prediccionrpart<-predict(modelorpart, ttesting, probability=TRUE)
prediccionsvm.rocr <- prediction(attr(prediccionsvm, "probabilities")[,2], ttesting$PurchasedBike)
prediccionrpart.rocr <- prediction(prediccionrpart[,1], ttesting$PurchasedBike)
prediccionsvm.perf <- performance(prediccionsvm.rocr, "tpr", "fpr")
prediccionrpart.perf <- performance(prediccionrpart.rocr, "fpr", "tpr" )
plot(prediccionsvm.perf, main="Curva ROC", col="blue")
plot(prediccionrpart.perf, col="red", add=TRUE)
lines(c(0,1), c(0,1), col="black")
#El area bajo la curva, AUC, esta dada por:
AUCsvm<-as.numeric(slot(performance(prediccionsvm.rocr,"auc"), "y.values"))
AUCsvm
AUCrpart<-1- as.numeric(slot(performance(prediccionrpart.rocr,"auc"), "y.values"))
AUCrpart
legend("bottomright", c(paste("SVM", "AUC:",round(AUCsvm, 3)), paste("rpart", "AUC:", round(AUCrpart,3))), lty = c(1,1), lwd=c(2.5,2.5),col=c("blue","red"))
library(rattle)
library(ggplot2)
##Instalacion y carga de las librerias necesarias
install.if.required <- function(x){
if(!require(x, character.only=TRUE)){
install.packages(x, dependencies = TRUE, character.only=TRUE)
library(class, character.only=TRUE)
}
}
lapply(c("class", "e1071", "ROCR","rpart"), install.if.required)
if(!require(class)){
install.packages("class", dependencies = TRUE)
library(class)
}
if(!require(e1071)){
install.packages("e1071", dependencies = TRUE)
library(e1071)
}
if(!require(ROCR)){#   install.packages("ROCR", dependencies = TRUE)
library(ROCR)
}
Datos<-read.table('Comprabicicletas.csv', sep=";", dec=".", header=T)
#Datos<-Datos[,-1] #Sacamos la primera columna de la ID de los clientes
head(Datos)
##Fijamos la semilla de modo de poder comparar los resultados
set.seed(30)
#Generamos una muestra donde el 70% de los datos seran utilizados como tabla de aprendizaje y el 30%como tabla de prueba (testing):
muestra <-sample(1:nrow(Datos),nrow(Datos)%/%(100/30))
ttesting<-Datos[muestra,]
taprendizaje<- Datos[-muestra,]
#Generamos el modelo utilizando la funcion kernel lineal:
modelosvm<-svm(PurchasedBike~.,data=taprendizaje, kernel="linear")
#Realizamos las predicciones sobre la tabla de prueba:
prediccionsvm<-predict(modelosvm, ttesting)
#Calculamos la matriz de confusion y la precision global:
MCsvm<-table(ttesting[,ncol(Datos)],prediccionsvm)
MCsvm
PGsvm<-(sum(diag(MCsvm)))/sum(MCsvm)
PGsvm
#Precision global y matriz de confusion para todos los datos
prediccionsvm.tablacompleta<-predict(modelosvm, Datos)
#Calculamos la matriz de confusion y la precision global:
MCsvm.tablacompleta<-table(Datos[,ncol(Datos)],prediccionsvm.tablacompleta)
MCsvm.tablacompleta
PGsvm.tablacompleta<-(sum(diag(MCsvm.tablacompleta)))/sum(MCsvm.tablacompleta)
PGsvm.tablacompleta
#Metodo de arbol para calcula la matriz de confusicon y la precision global de los datos d eprueba
library(rpart)  #LO MISMO PERO CON ARBOL
modelorpart<-rpart(PurchasedBike~.,data=taprendizaje)
prediccionrpart<-predict(modelorpart, ttesting, type="class")
MCrpart<-table(ttesting[,ncol(Datos)],prediccionrpart)
MCrpart
PGrpart<-(sum(diag(MCrpart)))/sum(MCrpart)
PGrpart
#Metodo de arboles de desicion para la tabla copleta
modelorpart<-rpart(PurchasedBike~.,data=taprendizaje)
prediccionrpart.tablacompleta<-predict(modelorpart, Datos, type="class")
MCrpart.tablacompleta<-table(Datos[,ncol(Datos)],prediccionrpart.tablacompleta)
MCrpart.tablacompleta
PGrpart.tablacompleta<-(sum(diag(MCrpart.tablacompleta)))/sum(MCrpart.tablacompleta)
PGrpart.tablacompleta
#El siguiente codigo permite construir la curva ROC sin la necesidad de recurrir a rattle:
modelosvm<-svm(PurchasedBike~.,data=taprendizaje, kernel="linear", probability=TRUE)
modelorpart<-rpart(PurchasedBike~.,data=taprendizaje)
prediccionsvm<-predict(modelosvm, ttesting, probability=TRUE)
prediccionrpart<-predict(modelorpart, ttesting, probability=TRUE)
prediccionsvm.rocr <- prediction(attr(prediccionsvm, "probabilities")[,2], ttesting$PurchasedBike)
prediccionrpart.rocr <- prediction(prediccionrpart[,1], ttesting$PurchasedBike)
prediccionsvm.perf <- performance(prediccionsvm.rocr, "tpr", "fpr")
prediccionrpart.perf <- performance(prediccionrpart.rocr, "fpr", "tpr" )
plot(prediccionsvm.perf, main="Curva ROC", col="blue")
plot(prediccionrpart.perf, col="red", add=TRUE)
lines(c(0,1), c(0,1), col="black")
#El area bajo la curva, AUC, esta dada por:
AUCsvm<-as.numeric(slot(performance(prediccionsvm.rocr,"auc"), "y.values"))
AUCsvm
AUCrpart<-1- as.numeric(slot(performance(prediccionrpart.rocr,"auc"), "y.values"))
AUCrpart
legend("bottomright", c(paste("SVM", "AUC:",round(AUCsvm, 3)), paste("rpart", "AUC:", round(AUCrpart,3))), lty = c(1,1), lwd=c(2.5,2.5),col=c("blue","red"))
library(rattle)
library(ggplot2)
##Instalacion y carga de las librerias necesarias
install.if.required <- function(x){
if(!require(x, character.only=TRUE)){
install.packages(x, dependencies = TRUE, character.only=TRUE)
library(class, character.only=TRUE)
}
}
lapply(c("class", "e1071", "ROCR","rpart"), install.if.required)
if(!require(class)){
install.packages("class", dependencies = TRUE)
library(class)
}
if(!require(e1071)){
install.packages("e1071", dependencies = TRUE)
library(e1071)
}
if(!require(ROCR)){#   install.packages("ROCR", dependencies = TRUE)
library(ROCR)
}
Datos<-read.table('Comprabicicletas.csv', sep=";", dec=".", header=T)
#Datos<-Datos[,-1] #Sacamos la primera columna de la ID de los clientes
head(Datos)
##Fijamos la semilla de modo de poder comparar los resultados
set.seed(30)
#Generamos una muestra donde el 70% de los datos seran utilizados como tabla de aprendizaje y el 30%como tabla de prueba (testing):
muestra <-sample(1:nrow(Datos),nrow(Datos)%/%(100/30))
ttesting<-Datos[muestra,]
taprendizaje<- Datos[-muestra,]
#Generamos el modelo utilizando la funcion kernel lineal:
modelosvm<-svm(PurchasedBike~.,data=taprendizaje, kernel="linear")
#Realizamos las predicciones sobre la tabla de prueba:
prediccionsvm<-predict(modelosvm, ttesting)
#Calculamos la matriz de confusion y la precision global:
MCsvm<-table(ttesting[,ncol(Datos)],prediccionsvm)
MCsvm
PGsvm<-(sum(diag(MCsvm)))/sum(MCsvm)
PGsvm
#Precision global y matriz de confusion para todos los datos
prediccionsvm.tablacompleta<-predict(modelosvm, Datos)
#Calculamos la matriz de confusion y la precision global:
MCsvm.tablacompleta<-table(Datos[,ncol(Datos)],prediccionsvm.tablacompleta)
MCsvm.tablacompleta
PGsvm.tablacompleta<-(sum(diag(MCsvm.tablacompleta)))/sum(MCsvm.tablacompleta)
PGsvm.tablacompleta
#Metodo de arbol para calcula la matriz de confusicon y la precision global de los datos d eprueba
library(rpart)  #LO MISMO PERO CON ARBOL
modelorpart<-rpart(PurchasedBike~.,data=taprendizaje)
prediccionrpart<-predict(modelorpart, ttesting, type="class")
MCrpart<-table(ttesting[,ncol(Datos)],prediccionrpart)
MCrpart
PGrpart<-(sum(diag(MCrpart)))/sum(MCrpart)
PGrpart
#Metodo de arboles de desicion para la tabla copleta
modelorpart<-rpart(PurchasedBike~.,data=taprendizaje)
prediccionrpart.tablacompleta<-predict(modelorpart, Datos, type="class")
MCrpart.tablacompleta<-table(Datos[,ncol(Datos)],prediccionrpart.tablacompleta)
MCrpart.tablacompleta
PGrpart.tablacompleta<-(sum(diag(MCrpart.tablacompleta)))/sum(MCrpart.tablacompleta)
PGrpart.tablacompleta
#El siguiente codigo permite construir la curva ROC sin la necesidad de recurrir a rattle:
modelosvm<-svm(PurchasedBike~.,data=taprendizaje, kernel="linear", probability=TRUE)
modelorpart<-rpart(PurchasedBike~.,data=taprendizaje)
prediccionsvm<-predict(modelosvm, ttesting, probability=TRUE)
prediccionrpart<-predict(modelorpart, ttesting, probability=TRUE)
prediccionsvm.rocr <- prediction(attr(prediccionsvm, "probabilities")[,2], ttesting$PurchasedBike)
prediccionrpart.rocr <- prediction(prediccionrpart[,1], ttesting$PurchasedBike)
prediccionsvm.perf <- performance(prediccionsvm.rocr, "tpr", "fpr")
prediccionrpart.perf <- performance(prediccionrpart.rocr, "fpr", "tpr" )
plot(prediccionsvm.perf, main="Curva ROC", col="blue")
plot(prediccionrpart.perf, col="red", add=TRUE)
lines(c(0,1), c(0,1), col="black")
#El area bajo la curva, AUC, esta dada por:
AUCsvm<-as.numeric(slot(performance(prediccionsvm.rocr,"auc"), "y.values"))
AUCsvm
AUCrpart<-1- as.numeric(slot(performance(prediccionrpart.rocr,"auc"), "y.values"))
AUCrpart
legend("bottomright", c(paste("SVM", "AUC:",round(AUCsvm, 3)), paste("rpart", "AUC:", round(AUCrpart,3))), lty = c(1,1), lwd=c(2.5,2.5),col=c("blue","red"))
MCsvm
PGsvm
MCsvm.tablacompleta
PGsvm.tablacompleta<-(sum(diag(MCsvm.tablacompleta)))/sum(MCsvm.tablacompleta)
PGsvm.tablacompleta
MCrpart
PGrpart<-(sum(diag(MCrpart)))/sum(MCrpart)
PGrpart
MCrpart.tablacompleta
PGrpart.tablacompleta<-(sum(diag(MCrpart.tablacompleta)))/sum(MCrpart.tablacompleta)
PGrpart.tablacompleta
